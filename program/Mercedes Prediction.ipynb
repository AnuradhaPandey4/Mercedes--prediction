{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>76.26</td>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "      <td>x</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>80.62</td>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>78.02</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y  X0 X1  X2 X3 X4 X5 X6 X8  ...  X375  X376  X377  X378  X379  \\\n",
       "0   0  130.81   k  v  at  a  d  u  j  o  ...     0     0     1     0     0   \n",
       "1   6   88.53   k  t  av  e  d  y  l  o  ...     1     0     0     0     0   \n",
       "2   7   76.26  az  w   n  c  d  x  j  x  ...     0     0     0     0     0   \n",
       "3   9   80.62  az  t   n  f  d  x  l  e  ...     0     0     0     0     0   \n",
       "4  13   78.02  az  v   n  f  d  h  d  n  ...     0     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     1     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_df.dtypes=='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 378)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 159)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy=pd.get_dummies(train_df.iloc[:,1:8])\n",
    "dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'y', 'X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X8',\n",
       "       ...\n",
       "       'X375', 'X376', 'X377', 'X378', 'X379', 'X380', 'X382', 'X383', 'X384',\n",
       "       'X385'],\n",
       "      dtype='object', length=378)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df.drop(['ID','X0','X1','X2','X3','X4','X5','X6','X8'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 369 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        y  X10  X11  X12  X13  X14  X15  X16  X17  X18  ...  X375  X376  X377  \\\n",
       "0  130.81    0    0    0    1    0    0    0    0    1  ...     0     0     1   \n",
       "1   88.53    0    0    0    0    0    0    0    0    1  ...     1     0     0   \n",
       "2   76.26    0    0    0    0    0    0    0    1    0  ...     0     0     0   \n",
       "3   80.62    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
       "4   78.02    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
       "\n",
       "   X378  X379  X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0  \n",
       "2     0     0     0     1     0     0     0  \n",
       "3     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 369 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.concat([dummy,train_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>X0_a</th>\n",
       "      <th>X0_aa</th>\n",
       "      <th>X0_ab</th>\n",
       "      <th>X0_ac</th>\n",
       "      <th>X0_ad</th>\n",
       "      <th>X0_af</th>\n",
       "      <th>X0_ai</th>\n",
       "      <th>X0_aj</th>\n",
       "      <th>X0_ak</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 528 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        y  X0_a  X0_aa  X0_ab  X0_ac  X0_ad  X0_af  X0_ai  X0_aj  X0_ak  ...  \\\n",
       "0  130.81     0      0      0      0      0      0      0      0      0  ...   \n",
       "1   88.53     0      0      0      0      0      0      0      0      0  ...   \n",
       "2   76.26     0      0      0      0      0      0      0      0      0  ...   \n",
       "3   80.62     0      0      0      0      0      0      0      0      0  ...   \n",
       "4   78.02     0      0      0      0      0      0      0      0      0  ...   \n",
       "\n",
       "   X375  X376  X377  X378  X379  X380  X382  X383  X384  X385  \n",
       "0     0     0     1     0     0     0     0     0     0     0  \n",
       "1     1     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     1     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 528 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train=train_df.drop(['y'],axis=1)\n",
    "test=train_df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(train,test,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler1 = MinMaxScaler().fit(X_train)\n",
    "X_train=scaler1.transform(X_train)\n",
    "X_test=scaler1.transform(X_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2946, 526)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(128,kernel_initializer='normal',input_dim =X_train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(256,activation='relu'))\n",
    "NN_model.add(Dense(256,activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(2,activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2946 samples, validate on 1263 samples\n",
      "Epoch 1/150\n",
      "2946/2946 [==============================] - 2s 690us/step - loss: 1826.0376 - mse: 1826.0374 - mae: 27.5527 - val_loss: 109.9136 - val_mse: 109.9136 - val_mae: 8.2004\n",
      "Epoch 2/150\n",
      "2946/2946 [==============================] - 1s 470us/step - loss: 86.4084 - mse: 86.4084 - mae: 6.1449 - val_loss: 78.0244 - val_mse: 78.0244 - val_mae: 5.8744\n",
      "Epoch 3/150\n",
      "2946/2946 [==============================] - 1s 431us/step - loss: 75.5342 - mse: 75.5342 - mae: 5.5369 - val_loss: 74.5392 - val_mse: 74.5392 - val_mae: 5.7247\n",
      "Epoch 4/150\n",
      "2946/2946 [==============================] - 1s 398us/step - loss: 70.6066 - mse: 70.6066 - mae: 5.2844 - val_loss: 87.8905 - val_mse: 87.8905 - val_mae: 7.6788\n",
      "Epoch 5/150\n",
      "2946/2946 [==============================] - 1s 452us/step - loss: 73.1714 - mse: 73.1713 - mae: 5.5728 - val_loss: 71.5135 - val_mse: 71.5134 - val_mae: 5.7478\n",
      "Epoch 6/150\n",
      "2946/2946 [==============================] - 1s 459us/step - loss: 68.8535 - mse: 68.8535 - mae: 5.2922 - val_loss: 77.0809 - val_mse: 77.0809 - val_mae: 5.5524\n",
      "Epoch 7/150\n",
      "2946/2946 [==============================] - 1s 430us/step - loss: 71.8150 - mse: 71.8149 - mae: 5.5163 - val_loss: 75.5506 - val_mse: 75.5506 - val_mae: 5.6726\n",
      "Epoch 8/150\n",
      "2946/2946 [==============================] - 1s 430us/step - loss: 69.1684 - mse: 69.1684 - mae: 5.3894 - val_loss: 79.9428 - val_mse: 79.9428 - val_mae: 5.6112\n",
      "Epoch 9/150\n",
      "2946/2946 [==============================] - 1s 388us/step - loss: 66.1854 - mse: 66.1854 - mae: 5.2215 - val_loss: 73.9825 - val_mse: 73.9826 - val_mae: 5.9188\n",
      "Epoch 10/150\n",
      "2946/2946 [==============================] - 1s 411us/step - loss: 64.5824 - mse: 64.5824 - mae: 5.1837 - val_loss: 71.9307 - val_mse: 71.9307 - val_mae: 5.8013\n",
      "Epoch 11/150\n",
      "2946/2946 [==============================] - 1s 478us/step - loss: 67.4456 - mse: 67.4456 - mae: 5.3276 - val_loss: 75.8700 - val_mse: 75.8700 - val_mae: 6.3652\n",
      "Epoch 12/150\n",
      "2946/2946 [==============================] - 1s 483us/step - loss: 64.4374 - mse: 64.4374 - mae: 5.2589 - val_loss: 81.7683 - val_mse: 81.7683 - val_mae: 5.6595\n",
      "Epoch 13/150\n",
      "2946/2946 [==============================] - 1s 424us/step - loss: 66.3849 - mse: 66.3849 - mae: 5.3119 - val_loss: 76.3887 - val_mse: 76.3887 - val_mae: 6.1694\n",
      "Epoch 14/150\n",
      "2946/2946 [==============================] - 1s 408us/step - loss: 63.5598 - mse: 63.5598 - mae: 5.1666 - val_loss: 84.1997 - val_mse: 84.1998 - val_mae: 5.7702\n",
      "Epoch 15/150\n",
      "2946/2946 [==============================] - 1s 414us/step - loss: 61.0555 - mse: 61.0555 - mae: 5.0865 - val_loss: 76.5726 - val_mse: 76.5726 - val_mae: 6.2275\n",
      "Epoch 16/150\n",
      "2946/2946 [==============================] - 1s 460us/step - loss: 59.7237 - mse: 59.7237 - mae: 4.9440 - val_loss: 79.0319 - val_mse: 79.0319 - val_mae: 5.7462\n",
      "Epoch 17/150\n",
      "2946/2946 [==============================] - 1s 427us/step - loss: 58.7850 - mse: 58.7850 - mae: 4.9625 - val_loss: 77.7588 - val_mse: 77.7588 - val_mae: 5.7729\n",
      "Epoch 18/150\n",
      "2946/2946 [==============================] - 1s 423us/step - loss: 58.2936 - mse: 58.2936 - mae: 4.9975 - val_loss: 101.0399 - val_mse: 101.0399 - val_mae: 6.4428\n",
      "Epoch 19/150\n",
      "2946/2946 [==============================] - 1s 422us/step - loss: 57.7259 - mse: 57.7259 - mae: 4.9950 - val_loss: 82.3482 - val_mse: 82.3482 - val_mae: 6.7657\n",
      "Epoch 20/150\n",
      "2946/2946 [==============================] - 1s 409us/step - loss: 56.1185 - mse: 56.1185 - mae: 4.9599 - val_loss: 81.7059 - val_mse: 81.7060 - val_mae: 5.8354\n",
      "Epoch 21/150\n",
      "2946/2946 [==============================] - 1s 463us/step - loss: 53.7966 - mse: 53.7966 - mae: 4.7579 - val_loss: 83.7417 - val_mse: 83.7417 - val_mae: 6.1657\n",
      "Epoch 22/150\n",
      "2946/2946 [==============================] - 1s 451us/step - loss: 54.2579 - mse: 54.2579 - mae: 4.8192 - val_loss: 83.6269 - val_mse: 83.6269 - val_mae: 6.0106\n",
      "Epoch 23/150\n",
      "2946/2946 [==============================] - 1s 447us/step - loss: 53.0801 - mse: 53.0801 - mae: 4.7548 - val_loss: 87.2504 - val_mse: 87.2504 - val_mae: 7.0368\n",
      "Epoch 24/150\n",
      "2946/2946 [==============================] - 1s 425us/step - loss: 50.0600 - mse: 50.0600 - mae: 4.5973 - val_loss: 91.4288 - val_mse: 91.4288 - val_mae: 6.2691\n",
      "Epoch 25/150\n",
      "2946/2946 [==============================] - 1s 455us/step - loss: 54.1750 - mse: 54.1750 - mae: 4.9465 - val_loss: 111.0957 - val_mse: 111.0957 - val_mae: 8.4771\n",
      "Epoch 26/150\n",
      "2946/2946 [==============================] - 1s 436us/step - loss: 61.5454 - mse: 61.5454 - mae: 5.4341 - val_loss: 85.6942 - val_mse: 85.6942 - val_mae: 6.3698\n",
      "Epoch 27/150\n",
      "2946/2946 [==============================] - 1s 431us/step - loss: 47.0682 - mse: 47.0681 - mae: 4.4225 - val_loss: 90.5150 - val_mse: 90.5150 - val_mae: 6.2555\n",
      "Epoch 28/150\n",
      "2946/2946 [==============================] - 1s 413us/step - loss: 50.3012 - mse: 50.3012 - mae: 4.6558 - val_loss: 87.7768 - val_mse: 87.7768 - val_mae: 6.7694\n",
      "Epoch 29/150\n",
      "2946/2946 [==============================] - 1s 433us/step - loss: 44.0829 - mse: 44.0828 - mae: 4.2885 - val_loss: 88.2684 - val_mse: 88.2684 - val_mae: 6.3425\n",
      "Epoch 30/150\n",
      "2946/2946 [==============================] - 1s 469us/step - loss: 45.1209 - mse: 45.1209 - mae: 4.4457 - val_loss: 85.7993 - val_mse: 85.7993 - val_mae: 6.3888\n",
      "Epoch 31/150\n",
      "2946/2946 [==============================] - 1s 450us/step - loss: 45.5404 - mse: 45.5404 - mae: 4.4341 - val_loss: 101.6508 - val_mse: 101.6508 - val_mae: 6.7895\n",
      "Epoch 32/150\n",
      "2946/2946 [==============================] - 1s 463us/step - loss: 44.2554 - mse: 44.2554 - mae: 4.3850 - val_loss: 113.2982 - val_mse: 113.2982 - val_mae: 7.2212\n",
      "Epoch 33/150\n",
      "2946/2946 [==============================] - 1s 417us/step - loss: 55.7551 - mse: 55.7551 - mae: 5.1663 - val_loss: 112.1263 - val_mse: 112.1263 - val_mae: 7.9654\n",
      "Epoch 34/150\n",
      "2946/2946 [==============================] - 1s 392us/step - loss: 41.2833 - mse: 41.2833 - mae: 4.2926 - val_loss: 89.7589 - val_mse: 89.7589 - val_mae: 6.3132\n",
      "Epoch 35/150\n",
      "2946/2946 [==============================] - 1s 437us/step - loss: 39.9689 - mse: 39.9689 - mae: 4.0996 - val_loss: 103.5480 - val_mse: 103.5480 - val_mae: 7.7517\n",
      "Epoch 36/150\n",
      "2946/2946 [==============================] - 1s 419us/step - loss: 39.3947 - mse: 39.3947 - mae: 4.1457 - val_loss: 100.1994 - val_mse: 100.1994 - val_mae: 6.9890\n",
      "Epoch 37/150\n",
      "2946/2946 [==============================] - 1s 477us/step - loss: 39.3471 - mse: 39.3471 - mae: 4.1978 - val_loss: 95.5416 - val_mse: 95.5416 - val_mae: 7.1170\n",
      "Epoch 38/150\n",
      "2946/2946 [==============================] - 1s 443us/step - loss: 37.4650 - mse: 37.4650 - mae: 4.0441 - val_loss: 107.0542 - val_mse: 107.0542 - val_mae: 6.9521\n",
      "Epoch 39/150\n",
      "2946/2946 [==============================] - 1s 421us/step - loss: 39.0169 - mse: 39.0169 - mae: 4.1622 - val_loss: 113.2600 - val_mse: 113.2600 - val_mae: 8.1408\n",
      "Epoch 40/150\n",
      "2946/2946 [==============================] - 1s 433us/step - loss: 38.6572 - mse: 38.6572 - mae: 4.2095 - val_loss: 142.6914 - val_mse: 142.6914 - val_mae: 9.6353\n",
      "Epoch 41/150\n",
      "2946/2946 [==============================] - 1s 491us/step - loss: 44.6274 - mse: 44.6274 - mae: 4.6754 - val_loss: 114.3516 - val_mse: 114.3516 - val_mae: 7.1956\n",
      "Epoch 42/150\n",
      "2946/2946 [==============================] - 1s 418us/step - loss: 36.8990 - mse: 36.8990 - mae: 4.0891 - val_loss: 92.9888 - val_mse: 92.9888 - val_mae: 6.5821\n",
      "Epoch 43/150\n",
      "2946/2946 [==============================] - 1s 410us/step - loss: 35.7246 - mse: 35.7246 - mae: 4.1300 - val_loss: 97.9166 - val_mse: 97.9166 - val_mae: 6.6091\n",
      "Epoch 44/150\n",
      "2946/2946 [==============================] - 1s 392us/step - loss: 31.9570 - mse: 31.9570 - mae: 3.7412 - val_loss: 110.8378 - val_mse: 110.8379 - val_mae: 6.9680\n",
      "Epoch 45/150\n",
      "2946/2946 [==============================] - 1s 485us/step - loss: 34.9065 - mse: 34.9065 - mae: 4.0716 - val_loss: 104.4931 - val_mse: 104.4931 - val_mae: 7.2799\n",
      "Epoch 46/150\n",
      "2946/2946 [==============================] - 1s 423us/step - loss: 34.9446 - mse: 34.9446 - mae: 4.0192 - val_loss: 102.6683 - val_mse: 102.6683 - val_mae: 7.0869\n",
      "Epoch 47/150\n",
      "2946/2946 [==============================] - 1s 399us/step - loss: 36.8529 - mse: 36.8529 - mae: 4.2539 - val_loss: 105.0727 - val_mse: 105.0727 - val_mae: 6.8793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/150\n",
      "2946/2946 [==============================] - 1s 419us/step - loss: 38.2198 - mse: 38.2198 - mae: 4.1260 - val_loss: 100.5545 - val_mse: 100.5545 - val_mae: 6.6829\n",
      "Epoch 49/150\n",
      "2946/2946 [==============================] - 1s 441us/step - loss: 29.7612 - mse: 29.7612 - mae: 3.7564 - val_loss: 138.8129 - val_mse: 138.8129 - val_mae: 8.1019\n",
      "Epoch 50/150\n",
      "2946/2946 [==============================] - 1s 482us/step - loss: 30.2859 - mse: 30.2859 - mae: 3.8379 - val_loss: 114.8275 - val_mse: 114.8275 - val_mae: 7.4607\n",
      "Epoch 51/150\n",
      "2946/2946 [==============================] - 1s 430us/step - loss: 30.5517 - mse: 30.5517 - mae: 3.8811 - val_loss: 118.8465 - val_mse: 118.8465 - val_mae: 7.2024\n",
      "Epoch 52/150\n",
      "2946/2946 [==============================] - 1s 421us/step - loss: 33.3525 - mse: 33.3525 - mae: 3.9787 - val_loss: 104.2554 - val_mse: 104.2554 - val_mae: 7.1265\n",
      "Epoch 53/150\n",
      "2946/2946 [==============================] - 1s 387us/step - loss: 29.3664 - mse: 29.3664 - mae: 3.8009 - val_loss: 129.0378 - val_mse: 129.0378 - val_mae: 8.3870\n",
      "Epoch 54/150\n",
      "2946/2946 [==============================] - 1s 438us/step - loss: 27.0643 - mse: 27.0643 - mae: 3.6563 - val_loss: 100.6980 - val_mse: 100.6981 - val_mae: 6.8220\n",
      "Epoch 55/150\n",
      "2946/2946 [==============================] - 1s 454us/step - loss: 24.7960 - mse: 24.7960 - mae: 3.4231 - val_loss: 116.9372 - val_mse: 116.9372 - val_mae: 7.0557\n",
      "Epoch 56/150\n",
      "2946/2946 [==============================] - 1s 422us/step - loss: 24.2066 - mse: 24.2066 - mae: 3.3424 - val_loss: 107.8470 - val_mse: 107.8470 - val_mae: 6.8594\n",
      "Epoch 57/150\n",
      "2946/2946 [==============================] - 1s 404us/step - loss: 24.2585 - mse: 24.2585 - mae: 3.4491 - val_loss: 105.8120 - val_mse: 105.8120 - val_mae: 7.3128\n",
      "Epoch 58/150\n",
      "2946/2946 [==============================] - 1s 420us/step - loss: 25.3242 - mse: 25.3242 - mae: 3.5110 - val_loss: 101.4762 - val_mse: 101.4762 - val_mae: 6.6255\n",
      "Epoch 59/150\n",
      "2946/2946 [==============================] - 1s 411us/step - loss: 24.1097 - mse: 24.1097 - mae: 3.3114 - val_loss: 144.0627 - val_mse: 144.0627 - val_mae: 9.2818\n",
      "Epoch 60/150\n",
      "2946/2946 [==============================] - 2s 514us/step - loss: 32.4979 - mse: 32.4979 - mae: 4.0379 - val_loss: 126.4886 - val_mse: 126.4886 - val_mae: 7.3644\n",
      "Epoch 61/150\n",
      "2946/2946 [==============================] - 1s 430us/step - loss: 24.8919 - mse: 24.8919 - mae: 3.5295 - val_loss: 110.7674 - val_mse: 110.7674 - val_mae: 7.2410\n",
      "Epoch 62/150\n",
      "2946/2946 [==============================] - 1s 407us/step - loss: 22.9059 - mse: 22.9059 - mae: 3.3445 - val_loss: 119.5439 - val_mse: 119.5439 - val_mae: 7.1202\n",
      "Epoch 63/150\n",
      "2946/2946 [==============================] - 1s 418us/step - loss: 22.4348 - mse: 22.4348 - mae: 3.2464 - val_loss: 119.9522 - val_mse: 119.9521 - val_mae: 7.3571\n",
      "Epoch 64/150\n",
      "2946/2946 [==============================] - 1s 431us/step - loss: 23.7866 - mse: 23.7866 - mae: 3.4877 - val_loss: 108.2887 - val_mse: 108.2887 - val_mae: 6.7471\n",
      "Epoch 65/150\n",
      "2946/2946 [==============================] - 1s 456us/step - loss: 21.7925 - mse: 21.7925 - mae: 3.2341 - val_loss: 117.7552 - val_mse: 117.7552 - val_mae: 7.3780\n",
      "Epoch 66/150\n",
      "2946/2946 [==============================] - 1s 471us/step - loss: 20.4098 - mse: 20.4098 - mae: 3.1246 - val_loss: 121.5719 - val_mse: 121.5719 - val_mae: 7.4554\n",
      "Epoch 67/150\n",
      "2946/2946 [==============================] - 1s 435us/step - loss: 20.7608 - mse: 20.7608 - mae: 3.1643 - val_loss: 113.7649 - val_mse: 113.7649 - val_mae: 6.9610\n",
      "Epoch 68/150\n",
      "2946/2946 [==============================] - 1s 436us/step - loss: 20.3052 - mse: 20.3052 - mae: 3.1672 - val_loss: 118.2199 - val_mse: 118.2199 - val_mae: 7.4757\n",
      "Epoch 69/150\n",
      "2946/2946 [==============================] - 1s 415us/step - loss: 22.0836 - mse: 22.0836 - mae: 3.3365 - val_loss: 104.4272 - val_mse: 104.4272 - val_mae: 7.0161\n",
      "Epoch 70/150\n",
      "2946/2946 [==============================] - 1s 416us/step - loss: 22.7351 - mse: 22.7351 - mae: 3.3888 - val_loss: 126.2979 - val_mse: 126.2979 - val_mae: 7.5255\n",
      "Epoch 71/150\n",
      "2946/2946 [==============================] - 1s 411us/step - loss: 20.8547 - mse: 20.8547 - mae: 3.1697 - val_loss: 106.6266 - val_mse: 106.6266 - val_mae: 6.7731\n",
      "Epoch 72/150\n",
      "2946/2946 [==============================] - 1s 419us/step - loss: 19.2838 - mse: 19.2838 - mae: 3.0217 - val_loss: 109.7244 - val_mse: 109.7244 - val_mae: 6.8757\n",
      "Epoch 73/150\n",
      "2946/2946 [==============================] - 1s 407us/step - loss: 20.9151 - mse: 20.9151 - mae: 3.1458 - val_loss: 116.0465 - val_mse: 116.0465 - val_mae: 7.1169\n",
      "Epoch 74/150\n",
      "2946/2946 [==============================] - 1s 462us/step - loss: 21.1693 - mse: 21.1693 - mae: 3.1962 - val_loss: 116.8489 - val_mse: 116.8489 - val_mae: 7.1934\n",
      "Epoch 75/150\n",
      "2946/2946 [==============================] - 1s 455us/step - loss: 19.7315 - mse: 19.7315 - mae: 3.0765 - val_loss: 113.9920 - val_mse: 113.9920 - val_mae: 7.0198\n",
      "Epoch 76/150\n",
      "2946/2946 [==============================] - 1s 422us/step - loss: 18.0890 - mse: 18.0890 - mae: 2.9024 - val_loss: 124.5024 - val_mse: 124.5024 - val_mae: 7.4368\n",
      "Epoch 77/150\n",
      "2946/2946 [==============================] - 1s 430us/step - loss: 18.9432 - mse: 18.9432 - mae: 3.0179 - val_loss: 112.3384 - val_mse: 112.3384 - val_mae: 6.8643\n",
      "Epoch 78/150\n",
      "2946/2946 [==============================] - 1s 405us/step - loss: 21.2546 - mse: 21.2546 - mae: 3.2392 - val_loss: 117.0285 - val_mse: 117.0284 - val_mae: 7.2264\n",
      "Epoch 79/150\n",
      "2946/2946 [==============================] - 1s 486us/step - loss: 19.4525 - mse: 19.4525 - mae: 3.0799 - val_loss: 110.3512 - val_mse: 110.3512 - val_mae: 7.2738\n",
      "Epoch 80/150\n",
      "2946/2946 [==============================] - 1s 422us/step - loss: 18.5646 - mse: 18.5646 - mae: 2.9417 - val_loss: 132.0042 - val_mse: 132.0042 - val_mae: 7.3277\n",
      "Epoch 81/150\n",
      "2946/2946 [==============================] - 1s 398us/step - loss: 19.3010 - mse: 19.3010 - mae: 3.0318 - val_loss: 131.0412 - val_mse: 131.0412 - val_mae: 7.9532\n",
      "Epoch 82/150\n",
      "2946/2946 [==============================] - 1s 427us/step - loss: 18.3499 - mse: 18.3499 - mae: 2.9651 - val_loss: 132.7872 - val_mse: 132.7872 - val_mae: 8.0583\n",
      "Epoch 83/150\n",
      "2946/2946 [==============================] - 1s 416us/step - loss: 19.7383 - mse: 19.7383 - mae: 3.0989 - val_loss: 130.5467 - val_mse: 130.5467 - val_mae: 7.6003\n",
      "Epoch 84/150\n",
      "2946/2946 [==============================] - 1s 484us/step - loss: 20.0001 - mse: 20.0001 - mae: 3.1348 - val_loss: 117.4162 - val_mse: 117.4162 - val_mae: 7.0749\n",
      "Epoch 85/150\n",
      "2946/2946 [==============================] - 1s 439us/step - loss: 18.1455 - mse: 18.1455 - mae: 2.9231 - val_loss: 115.3642 - val_mse: 115.3642 - val_mae: 7.0456\n",
      "Epoch 86/150\n",
      "2946/2946 [==============================] - 1s 430us/step - loss: 19.6989 - mse: 19.6989 - mae: 3.1565 - val_loss: 135.7943 - val_mse: 135.7942 - val_mae: 7.7355\n",
      "Epoch 87/150\n",
      "2946/2946 [==============================] - 1s 424us/step - loss: 19.0412 - mse: 19.0412 - mae: 3.0648 - val_loss: 126.4488 - val_mse: 126.4488 - val_mae: 7.6989\n",
      "Epoch 88/150\n",
      "2946/2946 [==============================] - 1s 448us/step - loss: 17.4841 - mse: 17.4841 - mae: 2.8860 - val_loss: 119.4952 - val_mse: 119.4952 - val_mae: 7.5600\n",
      "Epoch 89/150\n",
      "2946/2946 [==============================] - 1s 429us/step - loss: 17.1743 - mse: 17.1743 - mae: 2.9045 - val_loss: 117.4914 - val_mse: 117.4914 - val_mae: 7.0573\n",
      "Epoch 90/150\n",
      "2946/2946 [==============================] - 1s 398us/step - loss: 17.0770 - mse: 17.0770 - mae: 2.8342 - val_loss: 125.7769 - val_mse: 125.7769 - val_mae: 7.5040\n",
      "Epoch 91/150\n",
      "2946/2946 [==============================] - 1s 462us/step - loss: 16.4888 - mse: 16.4888 - mae: 2.7664 - val_loss: 118.9200 - val_mse: 118.9200 - val_mae: 6.9621s: 15.4107 - mse: 15.4107 - mae\n",
      "Epoch 92/150\n",
      "2946/2946 [==============================] - 1s 410us/step - loss: 18.5878 - mse: 18.5878 - mae: 3.0486 - val_loss: 117.7195 - val_mse: 117.7196 - val_mae: 7.2384\n",
      "Epoch 93/150\n",
      "2946/2946 [==============================] - 1s 424us/step - loss: 16.3446 - mse: 16.3446 - mae: 2.7035 - val_loss: 130.5377 - val_mse: 130.5377 - val_mae: 7.5988\n",
      "Epoch 94/150\n",
      "2946/2946 [==============================] - 1s 399us/step - loss: 20.0070 - mse: 20.0070 - mae: 3.1284 - val_loss: 117.3993 - val_mse: 117.3993 - val_mae: 6.9049\n",
      "Epoch 95/150\n",
      "2946/2946 [==============================] - 1s 419us/step - loss: 17.8939 - mse: 17.8939 - mae: 2.9526 - val_loss: 132.7802 - val_mse: 132.7802 - val_mae: 7.7849\n",
      "Epoch 96/150\n",
      "2946/2946 [==============================] - 1s 411us/step - loss: 16.4478 - mse: 16.4478 - mae: 2.8047 - val_loss: 134.7081 - val_mse: 134.7081 - val_mae: 7.5520\n",
      "Epoch 97/150\n",
      "2946/2946 [==============================] - 1s 439us/step - loss: 17.7369 - mse: 17.7369 - mae: 2.9665 - val_loss: 116.8186 - val_mse: 116.8186 - val_mae: 7.1371\n",
      "Epoch 98/150\n",
      "2946/2946 [==============================] - 1s 426us/step - loss: 15.2735 - mse: 15.2735 - mae: 2.6447 - val_loss: 122.5555 - val_mse: 122.5555 - val_mae: 7.2530\n",
      "Epoch 99/150\n",
      "2946/2946 [==============================] - 1s 438us/step - loss: 16.0471 - mse: 16.0471 - mae: 2.7550 - val_loss: 123.7672 - val_mse: 123.7672 - val_mae: 7.7599\n",
      "Epoch 100/150\n",
      "2946/2946 [==============================] - 1s 419us/step - loss: 16.3464 - mse: 16.3464 - mae: 2.7820 - val_loss: 158.7249 - val_mse: 158.7249 - val_mae: 7.8852\n",
      "Epoch 101/150\n",
      "2946/2946 [==============================] - 1s 439us/step - loss: 24.6927 - mse: 24.6927 - mae: 3.3665 - val_loss: 110.2909 - val_mse: 110.2909 - val_mae: 7.1669\n",
      "Epoch 102/150\n",
      "2946/2946 [==============================] - 1s 416us/step - loss: 23.1234 - mse: 23.1234 - mae: 3.2950 - val_loss: 123.9088 - val_mse: 123.9088 - val_mae: 7.2196\n",
      "Epoch 103/150\n",
      "2946/2946 [==============================] - 1s 415us/step - loss: 15.5160 - mse: 15.5160 - mae: 2.6761 - val_loss: 126.7553 - val_mse: 126.7553 - val_mae: 7.3048\n",
      "Epoch 104/150\n",
      "2946/2946 [==============================] - 1s 415us/step - loss: 15.4052 - mse: 15.4052 - mae: 2.6937 - val_loss: 122.8969 - val_mse: 122.8969 - val_mae: 7.2749\n",
      "Epoch 105/150\n",
      "2946/2946 [==============================] - 1s 419us/step - loss: 16.5420 - mse: 16.5420 - mae: 2.8111 - val_loss: 121.6687 - val_mse: 121.6687 - val_mae: 7.1297\n",
      "Epoch 106/150\n",
      "2946/2946 [==============================] - 1s 416us/step - loss: 15.3768 - mse: 15.3768 - mae: 2.7243 - val_loss: 123.0754 - val_mse: 123.0754 - val_mae: 7.1240\n",
      "Epoch 107/150\n",
      "2946/2946 [==============================] - 1s 480us/step - loss: 15.0571 - mse: 15.0571 - mae: 2.6684 - val_loss: 121.6384 - val_mse: 121.6384 - val_mae: 7.2285\n",
      "Epoch 108/150\n",
      "2946/2946 [==============================] - 1s 421us/step - loss: 15.5546 - mse: 15.5546 - mae: 2.6834 - val_loss: 130.7163 - val_mse: 130.7163 - val_mae: 7.4202\n",
      "Epoch 109/150\n",
      "2946/2946 [==============================] - 1s 410us/step - loss: 15.1539 - mse: 15.1539 - mae: 2.7298 - val_loss: 116.7911 - val_mse: 116.7911 - val_mae: 7.1249\n",
      "Epoch 110/150\n",
      "2946/2946 [==============================] - 1s 480us/step - loss: 14.5517 - mse: 14.5517 - mae: 2.5676 - val_loss: 149.5884 - val_mse: 149.5884 - val_mae: 8.3787\n",
      "Epoch 111/150\n",
      "2946/2946 [==============================] - 1s 405us/step - loss: 19.8894 - mse: 19.8894 - mae: 3.1174 - val_loss: 125.2090 - val_mse: 125.2090 - val_mae: 7.3554\n",
      "Epoch 112/150\n",
      "2946/2946 [==============================] - 1s 404us/step - loss: 17.5657 - mse: 17.5657 - mae: 2.9052 - val_loss: 119.6320 - val_mse: 119.6320 - val_mae: 7.0742\n",
      "Epoch 113/150\n",
      "2946/2946 [==============================] - 1s 452us/step - loss: 15.6432 - mse: 15.6432 - mae: 2.7452 - val_loss: 116.3239 - val_mse: 116.3239 - val_mae: 7.0876\n",
      "Epoch 114/150\n",
      "2946/2946 [==============================] - 1s 463us/step - loss: 13.3267 - mse: 13.3267 - mae: 2.4666 - val_loss: 122.4911 - val_mse: 122.4911 - val_mae: 7.1263\n",
      "Epoch 115/150\n",
      "2946/2946 [==============================] - 1s 410us/step - loss: 13.4282 - mse: 13.4282 - mae: 2.4585 - val_loss: 124.6368 - val_mse: 124.6368 - val_mae: 7.2704\n",
      "Epoch 116/150\n",
      "2946/2946 [==============================] - 1s 391us/step - loss: 12.7177 - mse: 12.7177 - mae: 2.3591 - val_loss: 124.9026 - val_mse: 124.9026 - val_mae: 7.3820\n",
      "Epoch 117/150\n",
      "2946/2946 [==============================] - 1s 419us/step - loss: 14.8858 - mse: 14.8858 - mae: 2.6175 - val_loss: 119.9792 - val_mse: 119.9792 - val_mae: 7.1030\n",
      "Epoch 118/150\n",
      "2946/2946 [==============================] - 1s 424us/step - loss: 12.7422 - mse: 12.7422 - mae: 2.3697 - val_loss: 119.7635 - val_mse: 119.7635 - val_mae: 7.1703\n",
      "Epoch 119/150\n",
      "2946/2946 [==============================] - 1s 401us/step - loss: 13.0913 - mse: 13.0913 - mae: 2.4175 - val_loss: 117.3188 - val_mse: 117.3188 - val_mae: 7.1262\n",
      "Epoch 120/150\n",
      "2946/2946 [==============================] - 1s 476us/step - loss: 13.1491 - mse: 13.1491 - mae: 2.4484 - val_loss: 124.0443 - val_mse: 124.0443 - val_mae: 7.4880\n",
      "Epoch 121/150\n",
      "2946/2946 [==============================] - 1s 416us/step - loss: 13.1752 - mse: 13.1752 - mae: 2.4148 - val_loss: 122.0700 - val_mse: 122.0700 - val_mae: 7.3069\n",
      "Epoch 122/150\n",
      "2946/2946 [==============================] - 1s 453us/step - loss: 14.6403 - mse: 14.6403 - mae: 2.6800 - val_loss: 123.5465 - val_mse: 123.5465 - val_mae: 7.2322\n",
      "Epoch 123/150\n",
      "2946/2946 [==============================] - 1s 423us/step - loss: 16.1829 - mse: 16.1829 - mae: 2.7417 - val_loss: 130.3527 - val_mse: 130.3527 - val_mae: 8.3828\n",
      "Epoch 124/150\n",
      "2946/2946 [==============================] - 1s 413us/step - loss: 16.6698 - mse: 16.6698 - mae: 2.8385 - val_loss: 140.2969 - val_mse: 140.2969 - val_mae: 8.0564\n",
      "Epoch 125/150\n",
      "2946/2946 [==============================] - 1s 407us/step - loss: 18.6935 - mse: 18.6935 - mae: 3.0230 - val_loss: 119.3615 - val_mse: 119.3615 - val_mae: 7.1830\n",
      "Epoch 126/150\n",
      "2946/2946 [==============================] - 1s 427us/step - loss: 13.3727 - mse: 13.3727 - mae: 2.4922 - val_loss: 133.1139 - val_mse: 133.1139 - val_mae: 7.3015\n",
      "Epoch 127/150\n",
      "2946/2946 [==============================] - 1s 504us/step - loss: 13.1642 - mse: 13.1642 - mae: 2.4133 - val_loss: 121.4175 - val_mse: 121.4175 - val_mae: 7.2045\n",
      "Epoch 128/150\n",
      "2946/2946 [==============================] - 1s 435us/step - loss: 14.0858 - mse: 14.0858 - mae: 2.5598 - val_loss: 113.5332 - val_mse: 113.5332 - val_mae: 6.9821\n",
      "Epoch 129/150\n",
      "2946/2946 [==============================] - 1s 420us/step - loss: 14.0224 - mse: 14.0224 - mae: 2.5912 - val_loss: 132.3606 - val_mse: 132.3606 - val_mae: 7.88284.0216 - mse: 14.0216 - mae: 2.59\n",
      "Epoch 130/150\n",
      "2946/2946 [==============================] - 1s 508us/step - loss: 12.6067 - mse: 12.6067 - mae: 2.3833 - val_loss: 136.0694 - val_mse: 136.0694 - val_mae: 7.5678\n",
      "Epoch 131/150\n",
      "2946/2946 [==============================] - 1s 408us/step - loss: 14.0741 - mse: 14.0741 - mae: 2.5843 - val_loss: 117.0124 - val_mse: 117.0124 - val_mae: 7.1743\n",
      "Epoch 132/150\n",
      "2946/2946 [==============================] - 1s 430us/step - loss: 13.7820 - mse: 13.7819 - mae: 2.5008 - val_loss: 123.3988 - val_mse: 123.3988 - val_mae: 7.1611\n",
      "Epoch 133/150\n",
      "2946/2946 [==============================] - 1s 439us/step - loss: 13.5853 - mse: 13.5853 - mae: 2.4776 - val_loss: 114.2037 - val_mse: 114.2037 - val_mae: 7.1149\n",
      "Epoch 134/150\n",
      "2946/2946 [==============================] - 1s 437us/step - loss: 14.0273 - mse: 14.0273 - mae: 2.4154 - val_loss: 134.2490 - val_mse: 134.2490 - val_mae: 7.4390\n",
      "Epoch 135/150\n",
      "2946/2946 [==============================] - 1s 454us/step - loss: 15.6302 - mse: 15.6302 - mae: 2.6950 - val_loss: 117.9965 - val_mse: 117.9966 - val_mae: 7.2580\n",
      "Epoch 136/150\n",
      "2946/2946 [==============================] - 1s 452us/step - loss: 12.9756 - mse: 12.9756 - mae: 2.3451 - val_loss: 139.6702 - val_mse: 139.6702 - val_mae: 7.5335\n",
      "Epoch 137/150\n",
      "2946/2946 [==============================] - 1s 446us/step - loss: 11.7905 - mse: 11.7905 - mae: 2.2697 - val_loss: 119.0963 - val_mse: 119.0963 - val_mae: 7.2643\n",
      "Epoch 138/150\n",
      "2946/2946 [==============================] - 1s 441us/step - loss: 13.1891 - mse: 13.1891 - mae: 2.4772 - val_loss: 135.3550 - val_mse: 135.3550 - val_mae: 7.7489\n",
      "Epoch 139/150\n",
      "2946/2946 [==============================] - 1s 431us/step - loss: 19.9215 - mse: 19.9215 - mae: 3.0586 - val_loss: 130.1018 - val_mse: 130.1018 - val_mae: 7.2832\n",
      "Epoch 140/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2946/2946 [==============================] - 1s 434us/step - loss: 13.8943 - mse: 13.8943 - mae: 2.5369 - val_loss: 122.1418 - val_mse: 122.1418 - val_mae: 7.3087\n",
      "Epoch 141/150\n",
      "2946/2946 [==============================] - 1s 415us/step - loss: 13.9880 - mse: 13.9880 - mae: 2.5723 - val_loss: 121.8456 - val_mse: 121.8457 - val_mae: 7.0981\n",
      "Epoch 142/150\n",
      "2946/2946 [==============================] - 1s 391us/step - loss: 14.1942 - mse: 14.1942 - mae: 2.5562 - val_loss: 109.7577 - val_mse: 109.7577 - val_mae: 7.1663\n",
      "Epoch 143/150\n",
      "2946/2946 [==============================] - 1s 426us/step - loss: 13.8458 - mse: 13.8458 - mae: 2.5048 - val_loss: 132.1255 - val_mse: 132.1255 - val_mae: 7.2669\n",
      "Epoch 144/150\n",
      "2946/2946 [==============================] - 1s 478us/step - loss: 18.3385 - mse: 18.3385 - mae: 3.0389 - val_loss: 116.6231 - val_mse: 116.6231 - val_mae: 7.1996loss: 17.9499 - mse: 17.9499 - mae: \n",
      "Epoch 145/150\n",
      "2946/2946 [==============================] - 1s 417us/step - loss: 13.1738 - mse: 13.1738 - mae: 2.3951 - val_loss: 130.2465 - val_mse: 130.2465 - val_mae: 7.2946\n",
      "Epoch 146/150\n",
      "2946/2946 [==============================] - 1s 440us/step - loss: 12.7129 - mse: 12.7129 - mae: 2.3809 - val_loss: 120.4423 - val_mse: 120.4423 - val_mae: 7.2852\n",
      "Epoch 147/150\n",
      "2946/2946 [==============================] - 1s 455us/step - loss: 11.9159 - mse: 11.9159 - mae: 2.3077 - val_loss: 124.5459 - val_mse: 124.5459 - val_mae: 7.1896\n",
      "Epoch 148/150\n",
      "2946/2946 [==============================] - 1s 450us/step - loss: 11.1044 - mse: 11.1044 - mae: 2.1428 - val_loss: 121.0967 - val_mse: 121.0967 - val_mae: 7.5128\n",
      "Epoch 149/150\n",
      "2946/2946 [==============================] - 1s 426us/step - loss: 13.5974 - mse: 13.5974 - mae: 2.5086 - val_loss: 133.0942 - val_mse: 133.0942 - val_mae: 7.6473\n",
      "Epoch 150/150\n",
      "2946/2946 [==============================] - 1s 437us/step - loss: 13.4887 - mse: 13.4887 - mae: 2.4772 - val_loss: 128.9294 - val_mse: 128.9294 - val_mae: 7.3558\n"
     ]
    }
   ],
   "source": [
    "history=NN_model.fit(X_train, y_train, epochs=150, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_mse', 'val_mae', 'loss', 'mse', 'mae'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
