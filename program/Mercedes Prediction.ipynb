{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('train.csv')\n",
    "test_df=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(train_df)\n",
    "y_train = train_df['y']\n",
    "id_test = test_df['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['ID', 'y'], axis=1, inplace=True)\n",
    "test_df.drop(['ID'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "      <td>x</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 376 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X0 X1  X2 X3 X4 X5 X6 X8  X10  X11  ...  X375  X376  X377  X378  X379  \\\n",
       "0   k  v  at  a  d  u  j  o    0    0  ...     0     0     1     0     0   \n",
       "1   k  t  av  e  d  y  l  o    0    0  ...     1     0     0     0     0   \n",
       "2  az  w   n  c  d  x  j  x    0    0  ...     0     0     0     0     0   \n",
       "3  az  t   n  f  d  x  l  e    0    0  ...     0     0     0     0     0   \n",
       "4  az  v   n  f  d  h  d  n    0    0  ...     0     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     1     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 376 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t</td>\n",
       "      <td>b</td>\n",
       "      <td>ai</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>b</td>\n",
       "      <td>g</td>\n",
       "      <td>y</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>as</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>j</td>\n",
       "      <td>j</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>az</td>\n",
       "      <td>l</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>z</td>\n",
       "      <td>l</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w</td>\n",
       "      <td>s</td>\n",
       "      <td>as</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>i</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 376 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X0 X1  X2 X3 X4 X5 X6 X8  X10  X11  ...  X375  X376  X377  X378  X379  \\\n",
       "0  az  v   n  f  d  t  a  w    0    0  ...     0     0     0     1     0   \n",
       "1   t  b  ai  a  d  b  g  y    0    0  ...     0     0     1     0     0   \n",
       "2  az  v  as  f  d  a  j  j    0    0  ...     0     0     0     1     0   \n",
       "3  az  l   n  f  d  z  l  n    0    0  ...     0     0     0     1     0   \n",
       "4   w  s  as  c  d  y  i  m    0    0  ...     1     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     0     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 376 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "      <td>x</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 376 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X0 X1  X2 X3 X4 X5 X6 X8  X10  X11  ...  X375  X376  X377  X378  X379  \\\n",
       "0   k  v  at  a  d  u  j  o    0    0  ...     0     0     1     0     0   \n",
       "1   k  t  av  e  d  y  l  o    0    0  ...     1     0     0     0     0   \n",
       "2  az  w   n  c  d  x  j  x    0    0  ...     0     0     0     0     0   \n",
       "3  az  t   n  f  d  x  l  e    0    0  ...     0     0     0     0     0   \n",
       "4  az  v   n  f  d  h  d  n    0    0  ...     0     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     1     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 376 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.get_dummies(df_all, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>...</th>\n",
       "      <th>X8_p</th>\n",
       "      <th>X8_q</th>\n",
       "      <th>X8_r</th>\n",
       "      <th>X8_s</th>\n",
       "      <th>X8_t</th>\n",
       "      <th>X8_u</th>\n",
       "      <th>X8_v</th>\n",
       "      <th>X8_w</th>\n",
       "      <th>X8_x</th>\n",
       "      <th>X8_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 571 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X10  X11  X12  X13  X14  X15  X16  X17  X18  X19  ...  X8_p  X8_q  X8_r  \\\n",
       "0    0    0    0    1    0    0    0    0    1    0  ...     0     0     0   \n",
       "1    0    0    0    0    0    0    0    0    1    0  ...     0     0     0   \n",
       "2    0    0    0    0    0    0    0    1    0    0  ...     0     0     0   \n",
       "3    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
       "4    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
       "\n",
       "   X8_s  X8_t  X8_u  X8_v  X8_w  X8_x  X8_y  \n",
       "0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     1     0  \n",
       "3     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 571 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_all = scaler.fit_transform(df_all)\n",
    "\n",
    "X_train = df_all[:num_train]\n",
    "X_test = df_all[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 571)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 571)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(128,kernel_initializer='normal',input_dim =X_train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(256,activation='relu'))\n",
    "NN_model.add(Dense(256,activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(1,activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2946 samples, validate on 1263 samples\n",
      "Epoch 1/150\n",
      "2946/2946 [==============================] - 1s 202us/step - loss: 1740.7095 - mse: 1740.7091 - mae: 26.6781 - val_loss: 87.5249 - val_mse: 87.5249 - val_mae: 7.1762\n",
      "Epoch 2/150\n",
      "2946/2946 [==============================] - 0s 93us/step - loss: 95.8805 - mse: 95.8806 - mae: 6.5391 - val_loss: 69.8876 - val_mse: 69.8876 - val_mae: 6.5619\n",
      "Epoch 3/150\n",
      "2946/2946 [==============================] - 0s 108us/step - loss: 83.7518 - mse: 83.7518 - mae: 5.9497 - val_loss: 60.5817 - val_mse: 60.5818 - val_mae: 5.6874\n",
      "Epoch 4/150\n",
      "2946/2946 [==============================] - 1s 181us/step - loss: 80.9354 - mse: 80.9354 - mae: 5.8111 - val_loss: 58.7113 - val_mse: 58.7113 - val_mae: 5.5621\n",
      "Epoch 5/150\n",
      "2946/2946 [==============================] - 1s 195us/step - loss: 78.6133 - mse: 78.6133 - mae: 5.8234 - val_loss: 56.8122 - val_mse: 56.8122 - val_mae: 5.4372\n",
      "Epoch 6/150\n",
      "2946/2946 [==============================] - 1s 242us/step - loss: 77.3257 - mse: 77.3258 - mae: 5.7324 - val_loss: 56.0833 - val_mse: 56.0834 - val_mae: 5.2558\n",
      "Epoch 7/150\n",
      "2946/2946 [==============================] - 1s 202us/step - loss: 77.3978 - mse: 77.3978 - mae: 5.7861 - val_loss: 58.9767 - val_mse: 58.9767 - val_mae: 5.0408\n",
      "Epoch 8/150\n",
      "2946/2946 [==============================] - 1s 233us/step - loss: 75.6681 - mse: 75.6681 - mae: 5.6928 - val_loss: 58.0886 - val_mse: 58.0886 - val_mae: 5.1183\n",
      "Epoch 9/150\n",
      "2946/2946 [==============================] - 1s 180us/step - loss: 73.8105 - mse: 73.8105 - mae: 5.6422 - val_loss: 113.0991 - val_mse: 113.0990 - val_mae: 9.2584\n",
      "Epoch 10/150\n",
      "2946/2946 [==============================] - 1s 196us/step - loss: 84.6450 - mse: 84.6450 - mae: 6.2872 - val_loss: 58.0817 - val_mse: 58.0817 - val_mae: 5.3989\n",
      "Epoch 11/150\n",
      "2946/2946 [==============================] - 1s 198us/step - loss: 70.6356 - mse: 70.6356 - mae: 5.5009 - val_loss: 55.5948 - val_mse: 55.5948 - val_mae: 4.9921\n",
      "Epoch 12/150\n",
      "2946/2946 [==============================] - 1s 200us/step - loss: 71.3209 - mse: 71.3209 - mae: 5.6073 - val_loss: 92.4452 - val_mse: 92.4452 - val_mae: 8.0736\n",
      "Epoch 13/150\n",
      "2946/2946 [==============================] - 1s 192us/step - loss: 72.5656 - mse: 72.5656 - mae: 5.7314 - val_loss: 62.2152 - val_mse: 62.2152 - val_mae: 5.6424\n",
      "Epoch 14/150\n",
      "2946/2946 [==============================] - 1s 221us/step - loss: 65.2172 - mse: 65.2172 - mae: 5.3281 - val_loss: 61.5190 - val_mse: 61.5190 - val_mae: 5.4080\n",
      "Epoch 15/150\n",
      "2946/2946 [==============================] - 1s 193us/step - loss: 70.0866 - mse: 70.0866 - mae: 5.6267 - val_loss: 61.7433 - val_mse: 61.7433 - val_mae: 5.3849\n",
      "Epoch 16/150\n",
      "2946/2946 [==============================] - 1s 207us/step - loss: 64.2660 - mse: 64.2660 - mae: 5.3274 - val_loss: 66.5791 - val_mse: 66.5791 - val_mae: 6.1041\n",
      "Epoch 17/150\n",
      "2946/2946 [==============================] - 1s 193us/step - loss: 64.8558 - mse: 64.8558 - mae: 5.4987 - val_loss: 65.4535 - val_mse: 65.4535 - val_mae: 5.4435\n",
      "Epoch 18/150\n",
      "2946/2946 [==============================] - 1s 213us/step - loss: 59.1907 - mse: 59.1907 - mae: 5.0887 - val_loss: 70.0184 - val_mse: 70.0184 - val_mae: 6.1738\n",
      "Epoch 19/150\n",
      "2946/2946 [==============================] - 1s 213us/step - loss: 58.3545 - mse: 58.3545 - mae: 5.1265 - val_loss: 68.4181 - val_mse: 68.4181 - val_mae: 5.6387\n",
      "Epoch 20/150\n",
      "2946/2946 [==============================] - 1s 193us/step - loss: 53.5967 - mse: 53.5967 - mae: 4.8758 - val_loss: 75.2520 - val_mse: 75.2520 - val_mae: 6.4484\n",
      "Epoch 21/150\n",
      "2946/2946 [==============================] - 1s 216us/step - loss: 64.1695 - mse: 64.1695 - mae: 5.6887 - val_loss: 96.5551 - val_mse: 96.5551 - val_mae: 6.9046\n",
      "Epoch 22/150\n",
      "2946/2946 [==============================] - 1s 250us/step - loss: 58.1166 - mse: 58.1166 - mae: 5.2502 - val_loss: 74.3471 - val_mse: 74.3471 - val_mae: 6.1852\n",
      "Epoch 23/150\n",
      "2946/2946 [==============================] - 1s 257us/step - loss: 55.7935 - mse: 55.7936 - mae: 5.1580 - val_loss: 72.6933 - val_mse: 72.6933 - val_mae: 5.6999\n",
      "Epoch 24/150\n",
      "2946/2946 [==============================] - 1s 310us/step - loss: 54.5635 - mse: 54.5635 - mae: 5.2025 - val_loss: 75.3268 - val_mse: 75.3268 - val_mae: 6.3969\n",
      "Epoch 25/150\n",
      "2946/2946 [==============================] - 1s 265us/step - loss: 46.9044 - mse: 46.9045 - mae: 4.6071 - val_loss: 72.1138 - val_mse: 72.1138 - val_mae: 5.9469\n",
      "Epoch 26/150\n",
      "2946/2946 [==============================] - 1s 292us/step - loss: 47.1628 - mse: 47.1628 - mae: 4.6710 - val_loss: 78.8061 - val_mse: 78.8061 - val_mae: 6.4906\n",
      "Epoch 27/150\n",
      "2946/2946 [==============================] - 1s 251us/step - loss: 47.2776 - mse: 47.2776 - mae: 4.7206 - val_loss: 69.9791 - val_mse: 69.9791 - val_mae: 5.8961\n",
      "Epoch 28/150\n",
      "2946/2946 [==============================] - 1s 201us/step - loss: 43.2840 - mse: 43.2840 - mae: 4.4783 - val_loss: 77.9977 - val_mse: 77.9977 - val_mae: 6.2633\n",
      "Epoch 29/150\n",
      "2946/2946 [==============================] - 1s 222us/step - loss: 45.8559 - mse: 45.8559 - mae: 4.6805 - val_loss: 78.4998 - val_mse: 78.4998 - val_mae: 6.4484\n",
      "Epoch 30/150\n",
      "2946/2946 [==============================] - 1s 185us/step - loss: 45.4331 - mse: 45.4330 - mae: 4.6266 - val_loss: 83.9518 - val_mse: 83.9518 - val_mae: 6.6837\n",
      "Epoch 31/150\n",
      "2946/2946 [==============================] - 1s 208us/step - loss: 42.0973 - mse: 42.0973 - mae: 4.4561 - val_loss: 87.2847 - val_mse: 87.2847 - val_mae: 6.5655\n",
      "Epoch 32/150\n",
      "2946/2946 [==============================] - 1s 190us/step - loss: 38.1651 - mse: 38.1651 - mae: 4.2493 - val_loss: 83.9724 - val_mse: 83.9724 - val_mae: 6.6753\n",
      "Epoch 33/150\n",
      "2946/2946 [==============================] - 1s 201us/step - loss: 38.3157 - mse: 38.3157 - mae: 4.3236 - val_loss: 92.2009 - val_mse: 92.2009 - val_mae: 6.9872\n",
      "Epoch 34/150\n",
      "2946/2946 [==============================] - 1s 197us/step - loss: 34.7032 - mse: 34.7032 - mae: 3.9940 - val_loss: 81.4071 - val_mse: 81.4071 - val_mae: 6.2490\n",
      "Epoch 35/150\n",
      "2946/2946 [==============================] - 1s 199us/step - loss: 33.7653 - mse: 33.7653 - mae: 4.0389 - val_loss: 87.3092 - val_mse: 87.3092 - val_mae: 6.7504\n",
      "Epoch 36/150\n",
      "2946/2946 [==============================] - 1s 207us/step - loss: 35.2475 - mse: 35.2475 - mae: 4.0972 - val_loss: 85.6106 - val_mse: 85.6106 - val_mae: 6.4758\n",
      "Epoch 37/150\n",
      "2946/2946 [==============================] - 1s 223us/step - loss: 32.7288 - mse: 32.7288 - mae: 3.9723 - val_loss: 100.2595 - val_mse: 100.2595 - val_mae: 7.4957\n",
      "Epoch 38/150\n",
      "2946/2946 [==============================] - 1s 200us/step - loss: 33.6245 - mse: 33.6245 - mae: 3.9706 - val_loss: 88.0418 - val_mse: 88.0418 - val_mae: 6.4630\n",
      "Epoch 39/150\n",
      "2946/2946 [==============================] - 1s 223us/step - loss: 31.0493 - mse: 31.0493 - mae: 3.8910 - val_loss: 91.3747 - val_mse: 91.3747 - val_mae: 6.6441\n",
      "Epoch 40/150\n",
      "2946/2946 [==============================] - 1s 246us/step - loss: 31.3207 - mse: 31.3207 - mae: 3.9900 - val_loss: 104.0973 - val_mse: 104.0973 - val_mae: 7.7081\n",
      "Epoch 41/150\n",
      "2946/2946 [==============================] - 1s 236us/step - loss: 30.1822 - mse: 30.1822 - mae: 3.8876 - val_loss: 88.5877 - val_mse: 88.5877 - val_mae: 6.6475\n",
      "Epoch 42/150\n",
      "2946/2946 [==============================] - 1s 238us/step - loss: 35.1708 - mse: 35.1708 - mae: 4.2555 - val_loss: 118.4949 - val_mse: 118.4949 - val_mae: 8.6897\n",
      "Epoch 43/150\n",
      "2946/2946 [==============================] - 1s 181us/step - loss: 28.1872 - mse: 28.1872 - mae: 3.7722 - val_loss: 106.3717 - val_mse: 106.3718 - val_mae: 7.5533\n",
      "Epoch 44/150\n",
      "2946/2946 [==============================] - 1s 216us/step - loss: 26.8855 - mse: 26.8855 - mae: 3.6855 - val_loss: 85.6947 - val_mse: 85.6947 - val_mae: 6.3276\n",
      "Epoch 45/150\n",
      "2946/2946 [==============================] - 1s 173us/step - loss: 25.7102 - mse: 25.7102 - mae: 3.5356 - val_loss: 100.4998 - val_mse: 100.4998 - val_mae: 7.0350\n",
      "Epoch 46/150\n",
      "2946/2946 [==============================] - 1s 193us/step - loss: 24.6256 - mse: 24.6256 - mae: 3.4922 - val_loss: 91.0067 - val_mse: 91.0067 - val_mae: 6.5302\n",
      "Epoch 47/150\n",
      "2946/2946 [==============================] - 0s 167us/step - loss: 22.9966 - mse: 22.9966 - mae: 3.3737 - val_loss: 97.7446 - val_mse: 97.7446 - val_mae: 6.8879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/150\n",
      "2946/2946 [==============================] - 1s 192us/step - loss: 25.3210 - mse: 25.3210 - mae: 3.5741 - val_loss: 94.3304 - val_mse: 94.3304 - val_mae: 6.8556\n",
      "Epoch 49/150\n",
      "2946/2946 [==============================] - 1s 171us/step - loss: 22.3672 - mse: 22.3672 - mae: 3.2947 - val_loss: 97.6298 - val_mse: 97.6298 - val_mae: 6.7118\n",
      "Epoch 50/150\n",
      "2946/2946 [==============================] - 1s 199us/step - loss: 23.5824 - mse: 23.5824 - mae: 3.4653 - val_loss: 162.9257 - val_mse: 162.9257 - val_mae: 10.2252\n",
      "Epoch 51/150\n",
      "2946/2946 [==============================] - 1s 188us/step - loss: 40.0598 - mse: 40.0598 - mae: 4.6818 - val_loss: 88.4262 - val_mse: 88.4262 - val_mae: 6.4941\n",
      "Epoch 52/150\n",
      "2946/2946 [==============================] - 1s 225us/step - loss: 22.5050 - mse: 22.5050 - mae: 3.3579 - val_loss: 91.2354 - val_mse: 91.2354 - val_mae: 6.7549\n",
      "Epoch 53/150\n",
      "2946/2946 [==============================] - 1s 242us/step - loss: 25.4121 - mse: 25.4121 - mae: 3.6558 - val_loss: 99.4639 - val_mse: 99.4639 - val_mae: 6.7652\n",
      "Epoch 54/150\n",
      "2946/2946 [==============================] - 1s 260us/step - loss: 21.4718 - mse: 21.4718 - mae: 3.2814 - val_loss: 96.7536 - val_mse: 96.7536 - val_mae: 6.8222\n",
      "Epoch 55/150\n",
      "2946/2946 [==============================] - 1s 256us/step - loss: 19.3227 - mse: 19.3227 - mae: 3.0014 - val_loss: 89.4527 - val_mse: 89.4527 - val_mae: 6.4933\n",
      "Epoch 56/150\n",
      "2946/2946 [==============================] - 1s 206us/step - loss: 20.3607 - mse: 20.3607 - mae: 3.1661 - val_loss: 107.8409 - val_mse: 107.8409 - val_mae: 7.6967\n",
      "Epoch 57/150\n",
      "2946/2946 [==============================] - 1s 218us/step - loss: 28.9824 - mse: 28.9824 - mae: 3.8792 - val_loss: 104.5262 - val_mse: 104.5262 - val_mae: 7.1356\n",
      "Epoch 58/150\n",
      "2946/2946 [==============================] - 1s 229us/step - loss: 20.3392 - mse: 20.3392 - mae: 3.1839 - val_loss: 94.8761 - val_mse: 94.8761 - val_mae: 6.7420\n",
      "Epoch 59/150\n",
      "2946/2946 [==============================] - 1s 220us/step - loss: 19.0283 - mse: 19.0283 - mae: 3.1015 - val_loss: 93.8651 - val_mse: 93.8650 - val_mae: 6.7208\n",
      "Epoch 60/150\n",
      "2946/2946 [==============================] - 1s 223us/step - loss: 20.6381 - mse: 20.6381 - mae: 3.2088 - val_loss: 88.6930 - val_mse: 88.6930 - val_mae: 6.6642\n",
      "Epoch 61/150\n",
      "2946/2946 [==============================] - 1s 358us/step - loss: 19.4310 - mse: 19.4310 - mae: 3.1285 - val_loss: 105.5612 - val_mse: 105.5612 - val_mae: 7.2868\n",
      "Epoch 62/150\n",
      "2946/2946 [==============================] - 1s 204us/step - loss: 20.3963 - mse: 20.3963 - mae: 3.2667 - val_loss: 92.9283 - val_mse: 92.9283 - val_mae: 6.6680\n",
      "Epoch 63/150\n",
      "2946/2946 [==============================] - 1s 198us/step - loss: 18.2172 - mse: 18.2172 - mae: 2.9558 - val_loss: 100.1110 - val_mse: 100.1110 - val_mae: 6.9354\n",
      "Epoch 64/150\n",
      "2946/2946 [==============================] - 1s 186us/step - loss: 17.6847 - mse: 17.6847 - mae: 2.9241 - val_loss: 107.3092 - val_mse: 107.3092 - val_mae: 7.2007\n",
      "Epoch 65/150\n",
      "2946/2946 [==============================] - 1s 207us/step - loss: 16.9349 - mse: 16.9349 - mae: 2.8143 - val_loss: 115.0931 - val_mse: 115.0930 - val_mae: 7.6756\n",
      "Epoch 66/150\n",
      "2946/2946 [==============================] - 1s 254us/step - loss: 17.4352 - mse: 17.4352 - mae: 2.8418 - val_loss: 90.2488 - val_mse: 90.2488 - val_mae: 6.5365\n",
      "Epoch 67/150\n",
      "2946/2946 [==============================] - 1s 271us/step - loss: 17.9902 - mse: 17.9902 - mae: 2.9124 - val_loss: 88.1857 - val_mse: 88.1857 - val_mae: 6.5303\n",
      "Epoch 68/150\n",
      "2946/2946 [==============================] - 1s 271us/step - loss: 17.0290 - mse: 17.0290 - mae: 2.8181 - val_loss: 105.1460 - val_mse: 105.1460 - val_mae: 7.1526\n",
      "Epoch 69/150\n",
      "2946/2946 [==============================] - 1s 256us/step - loss: 18.3107 - mse: 18.3107 - mae: 3.0132 - val_loss: 83.6588 - val_mse: 83.6588 - val_mae: 6.3166\n",
      "Epoch 70/150\n",
      "2946/2946 [==============================] - 1s 258us/step - loss: 16.1997 - mse: 16.1997 - mae: 2.7343 - val_loss: 83.2863 - val_mse: 83.2863 - val_mae: 6.3364\n",
      "Epoch 71/150\n",
      "2946/2946 [==============================] - 1s 275us/step - loss: 15.9942 - mse: 15.9942 - mae: 2.7359 - val_loss: 94.9306 - val_mse: 94.9306 - val_mae: 6.7120\n",
      "Epoch 72/150\n",
      "2946/2946 [==============================] - 1s 234us/step - loss: 16.3714 - mse: 16.3714 - mae: 2.7896 - val_loss: 109.3209 - val_mse: 109.3209 - val_mae: 7.8494\n",
      "Epoch 73/150\n",
      "2946/2946 [==============================] - 1s 241us/step - loss: 20.5297 - mse: 20.5297 - mae: 3.1779 - val_loss: 103.4858 - val_mse: 103.4858 - val_mae: 7.1523\n",
      "Epoch 74/150\n",
      "2946/2946 [==============================] - 1s 263us/step - loss: 14.7868 - mse: 14.7868 - mae: 2.6157 - val_loss: 122.5913 - val_mse: 122.5913 - val_mae: 8.1203\n",
      "Epoch 75/150\n",
      "2946/2946 [==============================] - 1s 216us/step - loss: 21.4850 - mse: 21.4850 - mae: 3.3281 - val_loss: 107.9849 - val_mse: 107.9849 - val_mae: 7.6718\n",
      "Epoch 76/150\n",
      "2946/2946 [==============================] - 1s 234us/step - loss: 15.8706 - mse: 15.8706 - mae: 2.7425 - val_loss: 88.7839 - val_mse: 88.7839 - val_mae: 6.4038\n",
      "Epoch 77/150\n",
      "2946/2946 [==============================] - 1s 210us/step - loss: 15.2493 - mse: 15.2493 - mae: 2.6489 - val_loss: 96.2146 - val_mse: 96.2146 - val_mae: 7.0440\n",
      "Epoch 78/150\n",
      "2946/2946 [==============================] - 1s 227us/step - loss: 15.7504 - mse: 15.7504 - mae: 2.7455 - val_loss: 89.6652 - val_mse: 89.6652 - val_mae: 6.5867\n",
      "Epoch 79/150\n",
      "2946/2946 [==============================] - 1s 203us/step - loss: 16.3464 - mse: 16.3464 - mae: 2.7260 - val_loss: 115.7768 - val_mse: 115.7768 - val_mae: 7.9681\n",
      "Epoch 80/150\n",
      "2946/2946 [==============================] - 1s 222us/step - loss: 17.8351 - mse: 17.8351 - mae: 2.9735 - val_loss: 89.5783 - val_mse: 89.5782 - val_mae: 6.4208\n",
      "Epoch 81/150\n",
      "2946/2946 [==============================] - 1s 205us/step - loss: 15.1909 - mse: 15.1909 - mae: 2.6571 - val_loss: 99.4700 - val_mse: 99.4700 - val_mae: 7.0397\n",
      "Epoch 82/150\n",
      "2946/2946 [==============================] - 1s 230us/step - loss: 16.4624 - mse: 16.4624 - mae: 2.8305 - val_loss: 89.1254 - val_mse: 89.1254 - val_mae: 6.5995\n",
      "Epoch 83/150\n",
      "2946/2946 [==============================] - 1s 222us/step - loss: 15.1685 - mse: 15.1685 - mae: 2.6329 - val_loss: 95.6927 - val_mse: 95.6927 - val_mae: 6.8500\n",
      "Epoch 84/150\n",
      "2946/2946 [==============================] - 1s 197us/step - loss: 16.0424 - mse: 16.0424 - mae: 2.7901 - val_loss: 90.0213 - val_mse: 90.0213 - val_mae: 6.4745\n",
      "Epoch 85/150\n",
      "2946/2946 [==============================] - 1s 210us/step - loss: 15.9657 - mse: 15.9657 - mae: 2.7975 - val_loss: 92.6734 - val_mse: 92.6734 - val_mae: 6.6493\n",
      "Epoch 86/150\n",
      "2946/2946 [==============================] - 1s 193us/step - loss: 14.4490 - mse: 14.4490 - mae: 2.5848 - val_loss: 90.8236 - val_mse: 90.8236 - val_mae: 6.5247\n",
      "Epoch 87/150\n",
      "2946/2946 [==============================] - 1s 216us/step - loss: 14.4915 - mse: 14.4915 - mae: 2.5807 - val_loss: 84.3835 - val_mse: 84.3835 - val_mae: 6.3400\n",
      "Epoch 88/150\n",
      "2946/2946 [==============================] - 1s 211us/step - loss: 14.6622 - mse: 14.6622 - mae: 2.5461 - val_loss: 91.2724 - val_mse: 91.2724 - val_mae: 6.5709\n",
      "Epoch 89/150\n",
      "2946/2946 [==============================] - 1s 242us/step - loss: 15.2728 - mse: 15.2728 - mae: 2.7065 - val_loss: 95.8016 - val_mse: 95.8016 - val_mae: 6.6588\n",
      "Epoch 90/150\n",
      "2946/2946 [==============================] - 1s 204us/step - loss: 14.3150 - mse: 14.3150 - mae: 2.5377 - val_loss: 100.4885 - val_mse: 100.4885 - val_mae: 7.0014\n",
      "Epoch 91/150\n",
      "2946/2946 [==============================] - 1s 243us/step - loss: 14.9418 - mse: 14.9418 - mae: 2.6784 - val_loss: 92.5612 - val_mse: 92.5612 - val_mae: 6.6679\n",
      "Epoch 92/150\n",
      "2946/2946 [==============================] - 1s 210us/step - loss: 16.3648 - mse: 16.3648 - mae: 2.8175 - val_loss: 86.9874 - val_mse: 86.9874 - val_mae: 6.4496\n",
      "Epoch 93/150\n",
      "2946/2946 [==============================] - 1s 206us/step - loss: 14.3533 - mse: 14.3533 - mae: 2.5573 - val_loss: 88.5485 - val_mse: 88.5485 - val_mae: 6.4104\n",
      "Epoch 94/150\n",
      "2946/2946 [==============================] - 1s 214us/step - loss: 14.4388 - mse: 14.4388 - mae: 2.6312 - val_loss: 99.4406 - val_mse: 99.4406 - val_mae: 7.0376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/150\n",
      "2946/2946 [==============================] - 1s 194us/step - loss: 17.8046 - mse: 17.8046 - mae: 2.9173 - val_loss: 99.5322 - val_mse: 99.5322 - val_mae: 7.2374\n",
      "Epoch 96/150\n",
      "2946/2946 [==============================] - 1s 213us/step - loss: 15.5575 - mse: 15.5575 - mae: 2.7814 - val_loss: 89.8538 - val_mse: 89.8538 - val_mae: 6.4901\n",
      "Epoch 97/150\n",
      "2946/2946 [==============================] - 1s 197us/step - loss: 15.2588 - mse: 15.2588 - mae: 2.6188 - val_loss: 90.4591 - val_mse: 90.4591 - val_mae: 6.7653\n",
      "Epoch 98/150\n",
      "2946/2946 [==============================] - 1s 213us/step - loss: 13.8275 - mse: 13.8275 - mae: 2.5244 - val_loss: 86.4591 - val_mse: 86.4591 - val_mae: 6.4535\n",
      "Epoch 99/150\n",
      "2946/2946 [==============================] - 1s 210us/step - loss: 14.3139 - mse: 14.3139 - mae: 2.5796 - val_loss: 86.5241 - val_mse: 86.5241 - val_mae: 6.3255\n",
      "Epoch 100/150\n",
      "2946/2946 [==============================] - 1s 218us/step - loss: 14.0516 - mse: 14.0516 - mae: 2.4970 - val_loss: 93.2585 - val_mse: 93.2585 - val_mae: 6.6328\n",
      "Epoch 101/150\n",
      "2946/2946 [==============================] - 1s 197us/step - loss: 13.1860 - mse: 13.1860 - mae: 2.4031 - val_loss: 81.7790 - val_mse: 81.7790 - val_mae: 6.1366\n",
      "Epoch 102/150\n",
      "2946/2946 [==============================] - 1s 216us/step - loss: 12.4910 - mse: 12.4910 - mae: 2.2984 - val_loss: 96.7434 - val_mse: 96.7434 - val_mae: 6.7319\n",
      "Epoch 103/150\n",
      "2946/2946 [==============================] - 1s 198us/step - loss: 12.7712 - mse: 12.7712 - mae: 2.3496 - val_loss: 92.3197 - val_mse: 92.3197 - val_mae: 6.7140\n",
      "Epoch 104/150\n",
      "2946/2946 [==============================] - 1s 223us/step - loss: 15.1411 - mse: 15.1411 - mae: 2.6576 - val_loss: 91.5651 - val_mse: 91.5651 - val_mae: 6.5140\n",
      "Epoch 105/150\n",
      "2946/2946 [==============================] - 1s 211us/step - loss: 14.2653 - mse: 14.2653 - mae: 2.5570 - val_loss: 85.8675 - val_mse: 85.8675 - val_mae: 6.3583\n",
      "Epoch 106/150\n",
      "2946/2946 [==============================] - 1s 201us/step - loss: 13.2089 - mse: 13.2089 - mae: 2.4347 - val_loss: 85.4521 - val_mse: 85.4521 - val_mae: 6.3015\n",
      "Epoch 107/150\n",
      "2946/2946 [==============================] - 1s 216us/step - loss: 12.5026 - mse: 12.5026 - mae: 2.3051 - val_loss: 95.2646 - val_mse: 95.2646 - val_mae: 6.8464\n",
      "Epoch 108/150\n",
      "2946/2946 [==============================] - 1s 196us/step - loss: 13.6633 - mse: 13.6633 - mae: 2.5097 - val_loss: 83.6159 - val_mse: 83.6159 - val_mae: 6.2796\n",
      "Epoch 109/150\n",
      "2946/2946 [==============================] - 1s 219us/step - loss: 13.4063 - mse: 13.4063 - mae: 2.4686 - val_loss: 96.6185 - val_mse: 96.6185 - val_mae: 6.7729\n",
      "Epoch 110/150\n",
      "2946/2946 [==============================] - 1s 205us/step - loss: 13.6173 - mse: 13.6173 - mae: 2.4925 - val_loss: 91.2047 - val_mse: 91.2048 - val_mae: 6.6034\n",
      "Epoch 111/150\n",
      "2946/2946 [==============================] - 1s 275us/step - loss: 12.5338 - mse: 12.5338 - mae: 2.2693 - val_loss: 100.7234 - val_mse: 100.7234 - val_mae: 7.0317\n",
      "Epoch 112/150\n",
      "2946/2946 [==============================] - 1s 299us/step - loss: 13.1480 - mse: 13.1480 - mae: 2.3688 - val_loss: 88.2550 - val_mse: 88.2550 - val_mae: 6.4921\n",
      "Epoch 113/150\n",
      "2946/2946 [==============================] - 1s 395us/step - loss: 12.3485 - mse: 12.3485 - mae: 2.3115 - val_loss: 94.6815 - val_mse: 94.6815 - val_mae: 6.6892\n",
      "Epoch 114/150\n",
      "2946/2946 [==============================] - 1s 249us/step - loss: 12.3741 - mse: 12.3741 - mae: 2.3296 - val_loss: 98.8784 - val_mse: 98.8784 - val_mae: 7.1357\n",
      "Epoch 115/150\n",
      "2946/2946 [==============================] - ETA: 0s - loss: 13.4173 - mse: 13.4173 - mae: 2.539 - 1s 242us/step - loss: 13.6888 - mse: 13.6888 - mae: 2.5341 - val_loss: 88.0653 - val_mse: 88.0653 - val_mae: 6.5207\n",
      "Epoch 116/150\n",
      "2946/2946 [==============================] - 1s 237us/step - loss: 11.9009 - mse: 11.9009 - mae: 2.2858 - val_loss: 96.4683 - val_mse: 96.4683 - val_mae: 6.9087\n",
      "Epoch 117/150\n",
      "2946/2946 [==============================] - 1s 234us/step - loss: 12.1009 - mse: 12.1009 - mae: 2.3157 - val_loss: 92.6346 - val_mse: 92.6346 - val_mae: 6.9466\n",
      "Epoch 118/150\n",
      "2946/2946 [==============================] - 1s 237us/step - loss: 15.0176 - mse: 15.0176 - mae: 2.7395 - val_loss: 91.7223 - val_mse: 91.7223 - val_mae: 6.6332\n",
      "Epoch 119/150\n",
      "2946/2946 [==============================] - 1s 226us/step - loss: 13.1616 - mse: 13.1616 - mae: 2.4013 - val_loss: 87.7148 - val_mse: 87.7148 - val_mae: 6.4565\n",
      "Epoch 120/150\n",
      "2946/2946 [==============================] - 1s 311us/step - loss: 12.4421 - mse: 12.4421 - mae: 2.2860 - val_loss: 86.4068 - val_mse: 86.4068 - val_mae: 6.4073\n",
      "Epoch 121/150\n",
      "2946/2946 [==============================] - 1s 249us/step - loss: 12.6183 - mse: 12.6183 - mae: 2.4003 - val_loss: 93.4729 - val_mse: 93.4729 - val_mae: 6.7416\n",
      "Epoch 122/150\n",
      "2946/2946 [==============================] - 1s 204us/step - loss: 13.0073 - mse: 13.0073 - mae: 2.3584 - val_loss: 87.3919 - val_mse: 87.3919 - val_mae: 6.5368\n",
      "Epoch 123/150\n",
      "2946/2946 [==============================] - 1s 223us/step - loss: 12.3865 - mse: 12.3865 - mae: 2.3148 - val_loss: 94.5398 - val_mse: 94.5398 - val_mae: 6.6593\n",
      "Epoch 124/150\n",
      "2946/2946 [==============================] - 1s 195us/step - loss: 11.7194 - mse: 11.7194 - mae: 2.2502 - val_loss: 82.3210 - val_mse: 82.3210 - val_mae: 6.2571\n",
      "Epoch 125/150\n",
      "2946/2946 [==============================] - 1s 251us/step - loss: 12.5106 - mse: 12.5106 - mae: 2.2738 - val_loss: 124.7940 - val_mse: 124.7940 - val_mae: 8.2257\n",
      "Epoch 126/150\n",
      "2946/2946 [==============================] - 1s 214us/step - loss: 14.9139 - mse: 14.9139 - mae: 2.7022 - val_loss: 97.7897 - val_mse: 97.7897 - val_mae: 6.9638\n",
      "Epoch 127/150\n",
      "2946/2946 [==============================] - 1s 207us/step - loss: 14.9115 - mse: 14.9115 - mae: 2.6872 - val_loss: 85.4913 - val_mse: 85.4913 - val_mae: 6.3764\n",
      "Epoch 128/150\n",
      "2946/2946 [==============================] - 1s 214us/step - loss: 12.7475 - mse: 12.7475 - mae: 2.3861 - val_loss: 95.3372 - val_mse: 95.3372 - val_mae: 6.7813\n",
      "Epoch 129/150\n",
      "2946/2946 [==============================] - 1s 195us/step - loss: 10.9498 - mse: 10.9498 - mae: 2.0625 - val_loss: 92.1528 - val_mse: 92.1527 - val_mae: 6.5777\n",
      "Epoch 130/150\n",
      "2946/2946 [==============================] - 1s 212us/step - loss: 11.0209 - mse: 11.0209 - mae: 2.1181 - val_loss: 94.5082 - val_mse: 94.5082 - val_mae: 6.6501\n",
      "Epoch 131/150\n",
      "2946/2946 [==============================] - 1s 195us/step - loss: 15.2275 - mse: 15.2275 - mae: 2.6291 - val_loss: 93.1467 - val_mse: 93.1467 - val_mae: 6.7728\n",
      "Epoch 132/150\n",
      "2946/2946 [==============================] - 1s 212us/step - loss: 10.9020 - mse: 10.9020 - mae: 2.0548 - val_loss: 91.4862 - val_mse: 91.4861 - val_mae: 6.5704\n",
      "Epoch 133/150\n",
      "2946/2946 [==============================] - 1s 200us/step - loss: 13.0145 - mse: 13.0145 - mae: 2.3795 - val_loss: 88.5488 - val_mse: 88.5488 - val_mae: 6.4591\n",
      "Epoch 134/150\n",
      "2946/2946 [==============================] - 1s 219us/step - loss: 11.5204 - mse: 11.5204 - mae: 2.2203 - val_loss: 91.4508 - val_mse: 91.4508 - val_mae: 6.5729\n",
      "Epoch 135/150\n",
      "2946/2946 [==============================] - 1s 242us/step - loss: 11.6902 - mse: 11.6902 - mae: 2.1928 - val_loss: 90.4089 - val_mse: 90.4089 - val_mae: 6.4702\n",
      "Epoch 136/150\n",
      "2946/2946 [==============================] - 1s 222us/step - loss: 11.1158 - mse: 11.1158 - mae: 2.1368 - val_loss: 97.3430 - val_mse: 97.3430 - val_mae: 6.9332\n",
      "Epoch 137/150\n",
      "2946/2946 [==============================] - 1s 214us/step - loss: 11.1572 - mse: 11.1572 - mae: 2.1039 - val_loss: 88.0854 - val_mse: 88.0853 - val_mae: 6.6578\n",
      "Epoch 138/150\n",
      "2946/2946 [==============================] - 1s 210us/step - loss: 14.3016 - mse: 14.3016 - mae: 2.5824 - val_loss: 86.2438 - val_mse: 86.2438 - val_mae: 6.3290\n",
      "Epoch 139/150\n",
      "2946/2946 [==============================] - 1s 218us/step - loss: 11.1364 - mse: 11.1364 - mae: 2.1284 - val_loss: 86.1763 - val_mse: 86.1763 - val_mae: 6.4690\n",
      "Epoch 140/150\n",
      "2946/2946 [==============================] - 1s 220us/step - loss: 10.6422 - mse: 10.6422 - mae: 2.0835 - val_loss: 88.1058 - val_mse: 88.1058 - val_mae: 6.4603\n",
      "Epoch 141/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2946/2946 [==============================] - 1s 256us/step - loss: 10.5987 - mse: 10.5987 - mae: 2.0450 - val_loss: 97.9496 - val_mse: 97.9496 - val_mae: 7.0558\n",
      "Epoch 142/150\n",
      "2946/2946 [==============================] - 1s 304us/step - loss: 15.6337 - mse: 15.6337 - mae: 2.6483 - val_loss: 89.4235 - val_mse: 89.4235 - val_mae: 6.4025\n",
      "Epoch 143/150\n",
      "2946/2946 [==============================] - 1s 368us/step - loss: 12.3420 - mse: 12.3420 - mae: 2.3322 - val_loss: 88.3292 - val_mse: 88.3292 - val_mae: 6.5039\n",
      "Epoch 144/150\n",
      "2946/2946 [==============================] - 1s 303us/step - loss: 11.1075 - mse: 11.1075 - mae: 2.1336 - val_loss: 90.0227 - val_mse: 90.0227 - val_mae: 6.5766\n",
      "Epoch 145/150\n",
      "2946/2946 [==============================] - 1s 243us/step - loss: 10.3905 - mse: 10.3905 - mae: 2.0114 - val_loss: 87.1408 - val_mse: 87.1408 - val_mae: 6.4954\n",
      "Epoch 146/150\n",
      "2946/2946 [==============================] - 1s 203us/step - loss: 10.2269 - mse: 10.2269 - mae: 2.0491 - val_loss: 85.8022 - val_mse: 85.8023 - val_mae: 6.3443\n",
      "Epoch 147/150\n",
      "2946/2946 [==============================] - 1s 236us/step - loss: 11.5041 - mse: 11.5041 - mae: 2.2109 - val_loss: 90.1704 - val_mse: 90.1704 - val_mae: 6.4951\n",
      "Epoch 148/150\n",
      "2946/2946 [==============================] - 1s 240us/step - loss: 10.9459 - mse: 10.9459 - mae: 2.0782 - val_loss: 84.4655 - val_mse: 84.4655 - val_mae: 6.3817\n",
      "Epoch 149/150\n",
      "2946/2946 [==============================] - 1s 247us/step - loss: 9.7897 - mse: 9.7897 - mae: 1.9659 - val_loss: 101.3519 - val_mse: 101.3519 - val_mae: 7.2103\n",
      "Epoch 150/150\n",
      "2946/2946 [==============================] - 1s 225us/step - loss: 11.3842 - mse: 11.3842 - mae: 2.2200 - val_loss: 87.8891 - val_mse: 87.8891 - val_mae: 6.5296\n"
     ]
    }
   ],
   "source": [
    "history=NN_model.fit(X_train, y_train, epochs=150, batch_size=32, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_mse', 'val_mae', 'loss', 'mse', 'mae'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=NN_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 78.61137 ]\n",
      " [ 98.95211 ]\n",
      " [ 80.05874 ]\n",
      " ...\n",
      " [ 87.23622 ]\n",
      " [118.792274]\n",
      " [ 92.76735 ]]\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
